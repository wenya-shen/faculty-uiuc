```
title: When Algorithmic Predictions Use Human-Generated Data: A Bias-Aware Classification Algorithm for Breast Cancer Diagnosis
authors: Mehmet Eren Ahsen, Mehmet Ulvi Saygi Ayvaci, Srinivasan Raghunathan
journal: Information Systems Research
published: 2019
```

# Executive Summary

*   This research investigates the design and value of a **bias-aware linear classification algorithm** for breast cancer diagnosis, where the algorithm utilizes human-generated data.
*   The core **theoretical** framework revolves around how **algorithms** that use data generated by humans inherit **biases**, thereby affecting their performance. The study proposes a **linear classifier** that accounts for **bias** in the input data, specifically focusing on the context of **breast cancer diagnosis**.
*   The study's main **finding** is that a **bias-aware algorithm** can eliminate the adverse impact of **bias** if the error in the mammogram assessment due to radiologist's **bias** has no variance. However, in the presence of error variance, the adverse impact of **bias** can be mitigated, but not eliminated, by the **bias-aware algorithm**.
*   The study argues that the **optimal bias-aware algorithm** assigns less (more) weight to the clinical-risk information (radiologist’s mammogram assessment) when the ==mean error== increases (decreases), but the reverse happens when the ==error variance== increases.
*   The study reveals scenarios where it might be better not to use clinical-risk information if it biases the radiologist's assessment.
*   Using data and point estimates obtained from mammography practice and medical literature, the **bias-aware algorithm** can significantly improve the expected patient life years or the accuracy of decisions based on mammography.

#Algorithms #Bias #BreastCancerDiagnosis #Classification #DecisionSupportSystems #Mammography #MedicalDecisionMaking #CognitiveBiases #LinearClassifier #ClinicalRiskInformation
<details>
  <summary>Click to expand</summary>
# 1. Introduction

*   **Algorithms** are increasingly used in decision-making across various domains, but they can be susceptible to human **biases** when the input data is human-generated [Agarwal and Dhar 2014].
*   Algorithms using human-generated decisions as inputs can inherit and even exacerbate **biases** [Coiera 2015, Barocas and Selbst 2016].
    *   This situation is seen in areas like loan approvals, job hiring, and law enforcement [Pasquale 2015].
	*   **Algorithms** that ignore **bias** may provide predictions that suffer from limitations akin to those provided by human beings, potentially worsening the errors [Coiera 2015, Barocas and Selbst 2016].
*   The study aims to design an **algorithm** that accounts for **bias** in input data, particularly in the context of a **clinical decision support system (CDSS)** for **breast cancer diagnosis**.
	*   The **CDSS** is a tool to help referring physicians make informed decisions based on **mammography**.
	*   This approach aligns with integrating **information systems (IS)** research methods and **behavioral economics** to address issues and inform **design science research** [Goes, 2013].

## 1.1. Role of Bias in Breast Cancer Diagnosis

*   In **breast cancer diagnosis**, referring physicians use radiologists' assessments, patient clinical-risk information, and patient preferences [Ayvaci et al. 2018].
*   Radiologists provide probabilistic risk assessments based on **mammogram** findings, often considering the patient's clinical-risk information.
*   The impact of clinical-risk information on radiologists’ assessments is debated; some argue it improves accuracy, while others suggest it may bias the radiologist [Loy and Irwig 2004, Elmore et al. 1997].
*   The radiologist’s assessment could be biased by the patient’s clinical-risk information [Carney et al. 2012].
	*   Undue influences resulting from radiologists’ cognitive **biases** may affect the performance of the referring physician.
*   A **CDSS** can be a valuable tool for referring physicians by helping them make recommendations on follow-up actions.
	*   An important component of such a **CDSS** is the **classification algorithm** that uses the **clinical-risk information** and **mammogram** assessment to predict the likelihood of cancer.
*   The study addresses three key research questions:
    *   What is the optimal design of a linear classification algorithm in the presence of radiologist **bias**?
    *   How does the **bias** affect the **algorithm’s** performance and design?
    *   Should the **clinical-risk information** be used at all in the diagnostic process given its potential to **bias** the radiologist?
*   The contributions of this research are:
    *   A new approach to designing a **bias-aware classification algorithm** and analyzing the impact of **bias** on the algorithm and its performance, which is new to the literature.
    *   Quantifying the value of **bias-aware algorithms** in the **breast-cancer-diagnosis** context.

# 2. Related Literature

*   The study is related to literature on cognitive **biases** in medical decision making, the design of **decision support systems (DSS)**, and mathematical modeling of **decision biases**.

## 2.1. Cognitive Biases in Radiological Diagnosis

*   The presence of **clinical-risk information** is critical in **breast-cancer-diagnostic** performance and may reflect features of various types of **biases**.
*   Three common **biases** are **anchoring**, confirmation, and availability, which occur when synthesizing information for medical decisions [Ogdie et al. 2012].
    *   **Anchoring bias**: The human tendency to overvalue a single piece of information.
	    *   In radiology, the radiologist may be anchored by the clinical history when assessing the radiographic image [Lee et al. 2013, Alpert and Hillman 2004].
	    *   To mitigate the **anchoring effect**, it has been suggested that radiologists look at the image first [Griscom 2002].
	*   **Confirmation bias**: The decision maker looks for confirming evidence to bolster an early assessment, rather than trying to disprove it.
	    *   An early judgment based on the patient’s **clinical-risk information** may induce a radiologist to focus on **mammogram** features consistent with the initial impression and ignore the features that conflict with it [Wallsten 1981].
	    *   **Confirmation bias** relates to a radiologist’s interpretation of findings in support of prior conclusions, while **anchoring** relates to overreliance on a single piece of information, the **clinical-risk information**.
	    *   **Confirmation bias** may amplify the **anchoring effect** in diagnostic decisions [Croskerry 2003].
    *   **Availability bias**: A person overestimates the probability of an event that comes immediately to the person’s mind.
	    *   The **clinical-risk information**, when available at the time of imaging interpretation, may nudge the radiologist to be more suspicious of any findings on an image [Eraker and Politser 1982].
	    *   **Availability bias** can occur when a person overestimates the probability of an event that comes immediately to the person’s mind.
	    *   Mamede et al. (2010) found that medical residents were susceptible to **availability bias**.

## 2.2. Related IS Research

*   The existing literature on **classification** under noisy data focuses mainly on the development of expert systems where decision rules are learned from training data [Hong and Tsang 1997, Wu et al. 2003, Saar-Tsechansky and Provost 2007].
    *   Researchers have developed input modification methods to eliminate the negative effects of noise in training data [Mookerjee 2001, Jiang et al. 2005].
*   A substream of the classification literature focuses on discriminating classes under strategically manipulated data [Dalvi et al. 2004].
    *   Researchers proposed methods for optimal classification [Boylu et al. 2010] or for approximate solutions [Boylu et al. 2007].
*   The study’s approach differs from previous studies by:
    *   Explicitly modeling the source of noise as human **biases** rather than strategic agents.
    *   Decomposing the source of noise into systematic and random parts.
    *   Providing theoretical insights into how input **bias** affects **algorithm** design and performance.

## 2.3. Related Decision Analytic Work

*   The **decision analysis** and operations management community is examining problems related to the mathematical modeling of **decision biases**.
    *   An optimization-based approach was proposed to determine the weights for biased quantile judgments [Bansal et al. 2017].
    *   Research has found that **bias** can be beneficial in coordinating the firms’ decisions [Li et al. 2017].
    *   A machine-learning mechanism was developed to alleviate overconfidence **bias** and the overfitting problem while aggregating forecasts [Grushka-Cockayne et al. 2016].
*   The study takes a prescriptive approach and studies how the **algorithm** should be designed to optimally aggregate information and make recommendations in the presence of biased data.

# 3. Model Description

*   The model considers a patient with an unknown true health status and a radiologist assessing the **mammogram** to determine the presence or absence of cancer.
*   The radiologist has access to the patient’s **clinical-risk information**.
*   Presence or absence of cancer is indicated using labels + and −, respectively.
*   The true (unbiased) risk implied by the patient’s **mammogram** (imaging) and the true risk implied by the patient’s **clinical-risk information** are denoted as xi and xc, respectively.
    *   Conditional on the true health status of the patient, xi and xc follow a bivariate-normal distribution.
*   Under **bias**, the radiologist’s estimate, ˆxi, deviates from xi.
    *   The error introduced by **bias** is a random variable that follows a probability distribution.
*   The mean error, β(xc − ¯xc), depends on:
    *   How much xc deviates from its population mean, ¯xc, which serves as the anchor.
    *   The **bias** factor β ≥ 0, which measures the radiologist’s inherent **bias** level.
*   σ0 captures the variability in the error introduced by **bias** [6].
    *   β  0 and σ0  0 correspond to the unbiased assessment of xi.
*   Given a biased assessment from a radiologist, the tasks of the **classification algorithm** (hereafter, **bias-aware algorithm**) are to (i) aggregate ˆxi and xc and (ii) determine a threshold k for the aggregated risk to classify the instance as + or −.
*   The aggregate information, r, is defined as:
    *   r : (1 − α) ˆxi + αxc ,
    *   where α denotes the weight assigned to xc, and 1 − α denotes the weight assigned to ˆxi.
*   The study focuses on exploring the role of **bias** in the design and performance of the **bias-aware algorithm** and not the ability of either type of risk information in discriminating the + cases from the − cases.
*   The following definitions are also used:
    *   I(α, β, σ0)  (μc − μn)/σ as the discriminative ability of r.
    *   ∆i  μci − μni and ∆c  μcc − μnc, respectively.
    *   h : I(0, 0, 0) / I(1, 0, 0)  ∆i / ∆c
    *   t : (UTP − UFN)/P(−) / (UTN − UFP)/P(+)  UTP − UFN / UTN − UFP · P(+) / P(−)

# 4. Theoretical Analysis

*   The analysis explores the optimal **bias-aware algorithm** based on the AUC and the expected utility objectives.
*   It examines how **bias** affects **algorithm** performance and quantifies the impact of ignoring **bias**.
*   The analysis identifies conditions under which it is suboptimal to use the **clinical-risk information** given that it can **bias** the radiologist’s assessment.
*   Finally, the study discusses the case when **bias** impacts error mean and error variance proportionally.

## 4.1. Optimal Bias-Aware Algorithm

*   The **optimal weight** and threshold are characterized in Theorem 1:
    *   α∗(β, σ0) : 1 / (1 + σi / σc (h − ρ) / (σ2 / i (1 − hρ) + σ2 / 0 − σi / σc / β(h − ρ)))
    *   k∗(β, σ0) : k(α∗(β, σ0), β, σ0).
*   Key observations from Theorem 1:
    *   Utility parameters only affect the optimal risk threshold and not the optimal aggregation weight.
    *   If t  1, the risk threshold is also independent of the utility parameters.
    *   When the radiologist is unbiased such that β  0 and σ0  0, the optimal weight for the **clinical-risk information** reduces to that shown by Winkler (1981).
    *   The optimal weight for the clinical-risk information can be negative depending on the relative discriminatory ability of the two risks, the correlation between them, and the **bias** parameters.
*   Structural analysis of the optimal weight:
    *   α∗(β, σ0) is decreasing in **bias** factor β.
    *   An increase in the error variance (σ0) increases the weight assigned to the **clinical-risk information**.
    *   An increase in the correlation between the **clinical-risk information** and the **mammogram** risk (ρ) decreases the weight assigned to the **clinical-risk information** when the error variance is not too high.
    *   The threshold level for risk to recommend a follow-up is increasing in both **bias** factor and error variance.

## 4.2. Impact of Bias Under the Optimal Bias-Aware Algorithm

*   Proposition 1 characterizes how the **bias** factor, error variance, and other model parameters affect the expected utility and the discriminative ability under the **optimal bias-aware algorithm**.
    *   U∗(β2 , σ0)  U∗(β1 , σ0) < U∗(β1 , 0)  U∗(0, 0),
    *   AUC∗(β2 , σ0)  AUC∗(β1 , σ0) < AUC∗(β1 , 0)  AUC∗(0, 0),
    *   U∗(β, σ0) is independent of β and decreases in σ0, σi, σc, and ρ.
*   According to Proposition 1, (i) and (ii), the expected utility and discriminative ability are (weakly) smaller in the presence of **bias** than in its absence even under the **bias-aware algorithm**.
*   When error variance is zero (i.e., σ0  0), the **optimal bias-aware algorithm** eliminates the negative impact of **bias**.
*   In the presence of a positive error variance (i.e., σ0 > 0), the negative effect of **bias** cannot be eliminated through the **optimal bias-aware algorithm** alone.
*   The optimal expected utility, U∗(β, σ0), is independent of the **bias** factor (and, therefore, the mean error), yet it decreases in the error variance.

## 4.3. Impact of Ignoring Bias in the Algorithm

*   The value of the **bias-aware algorithm** is defined as the optimal utility when the algorithm adjusts for **bias** less the utility when the algorithm assumes that **bias** does not exist.
*   The utility value of the **bias-aware algorithm** is defined as:
    *   V(β, σ0) : U∗(β, σ0) − U(α∗(0, 0), β, σ0 , k(α∗(0, 0), 0, 0)).
*   Proposition 2 characterizes how the **bias** affects the value of the **bias-aware algorithm**.
    *   The **bias-aware algorithm** has (i) V(β, σ0) ≥ 0, and (ii) V(β, σ0) is decreasing in β when β < σ2 / 0 /(σc σi · (h − ρ)) and increasing otherwise.
*   The value does not necessarily increase in the **bias** factor (β).
*   If there is no error variance (σ0  0), then an increase in mean error always increases the value of the **bias-aware algorithm**.
*   When the error variance is not zero, the value increases in the mean error only when the mean error is larger than a threshold.
    *   An increase in mean error mitigates the adverse impact of a large error variance for fixed values of α and k.
*   The interaction between the mean error and error variance due to **bias** is critical in determining the value of the **bias-aware algorithm**.

## 4.4. Should the Clinical-Risk Information Be Used Under Radiologist Bias?

*   The adverse impact of mean error alone due to **bias** can be eliminated, but an increase in the error variance diminishes the usefulness of the **clinical-risk information**.
*   The social planner can consider two possible alternatives:
    *   Use the **clinical-risk information** but design the algorithm to account for the **bias**.
    *   Not use the **clinical-risk information** at all.
*   Proposition 3 characterizes when the **clinical-risk information** should be available in the system despite the possibility that it may **bias** the radiologist.
    *   If h ≥ 1 and 1 / h − √(h2 − 1)σ2 / 0 / σ2 / i < ρ, then U∗(β, σ0) < U(0, 0, 0, k(α∗(0, 0), 0, 0)); otherwise, U∗(β, σ0) > U(0, 0, 0, k(α∗(0, 0), 0, 0)).
*   Insights from Proposition 3:
    *   Even when the **clinical-risk information** is informative on its own, not using it in the whole process may be better than using it.
    *   A high-enough correlation will cause the **clinical-risk information** to be not useful.
    *   An increase in the error variance (σ0) enlarges the region in the parameter space where not using the **clinical-risk information** is better than using it.
    *   When a diagnostic task is based on data derived from human experts susceptible to cognitive **biases**, the error variance induced by **bias** is a key factor to consider.

## 4.5. Joint Influence of Bias on Both the Mean Error and Error Variance

*   The baseline model assumes the radiologist’s **bias** influences the mean error and error variance in **mammogram** assessment independently.
*   Assuming that a shift in the **bias** factor has a proportional impact on mean error and error variance, the study models error due to **bias** conditional on **clinical-risk information** as ˆxi − xi | xc ∼ N (β(xc − ¯xc), βσ0).
*   Theorem 2 in Online Appendix B provides the optimal weight and risk threshold under the new model.
*   Proposition 4 suggests that when mean error and error variance are proportional, an increase in the **bias** factor always hurts the **optimal** expected utility or discriminative performance unless there is no error variance.
    *   U∗(β2 , σ0) < U∗(β1 , σ0) < U∗(β1 , 0)  U∗(0, 0),
    *   AUC∗(β2 , σ0) < AUC∗(β1 , σ0) < AUC∗(β1 , 0)  AUC∗(0, 0).
*   The main additional insight from the proposition is that when the **bias** factor influences both the mean error and error variance, the **bias-aware algorithm** alone cannot completely eliminate the adverse impact of **bias**.

# 5. Design and Value of the Bias-Aware Algorithm for Breast Cancer Diagnosis: A Computational Experiment

*   The study uses a **breast-cancer-outcomes database** based on **clinical-risk information** and the medical literature.

## 5.1. Parameter Estimation

*   The study uses the **Breast Cancer Surveillance Consortium (BCSC) database** to estimate the parameters of the **clinical-risk distributions**.
*   The parameters for the clinical-risk distributions are μpc  2.4042, μnc  2.1900, σpc  0.3656, and σnc  0.3869, and the indicated AUC of the clinical-risk information (AUCc) is 0.656.
*   The parameters for the **mammography** distributions are imputed using the performance benchmarks reported in the medical literature.
*   Three different AUC values for the **mammography** risk are selected to represent low (AUCi  0.780), moderate (AUCi  0.820), and high (AUCi  0.890) discriminative ability.
*   The correlation between **mammogram** and **clinical-risk information**, ρ, is estimated as 0.0548 using Spearman’s rank correlation.
*   The study estimates the disutility as the life years lost, following the medical literature.

## 5.2. Optimal Bias-Aware Algorithm: Aggregation Weights and Decision Threshold

*   For the prevailing **clinical-risk** model with an approximate AUC of 0.656 and an average-quality **mammogram** with an AUC of about 0.820, the **clinical-risk information** should carry a relative weight of approximately 24% and the **mammogram** risk should carry a relative weight of 76% under no **bias**.
*   Under no **bias**, a follow-up should be recommended if the weighted risk score exceeds a value of 2.62.
*   The **optimal weight** on the **clinical-risk information** (mammogram risk) generally decreases (increases) when either **bias** factor (β) increases or error variance (σ2 / 0 ) decreases.
*   When both **bias** factor and error variance are sufficiently high, it is optimal to use a larger weight for the **clinical-risk information** under **bias** than under no **bias**.
*   An accurate estimation of **bias** parameters is essential for the **optimal design** of a **bias-aware algorithm**.
*   An increase in any **bias** parameter only increases the threshold.

## 5.3. Impact of Radiologists’ Bias on Breast-Cancer-Diagnosis Outcomes

*   The impact of radiologists’ **bias** is quantified as the reduction in expected life years because of the presence of **bias**.
*   When the accuracy of the **mammography** is moderate (i.e., AUCi  0.820), for the prevailing **clinical-risk** models with AUCc  0.656, the presence of various levels of **bias** could result in a reduction in the expected life years for all patients ranging from 8.00 to 119.69.
*   The adverse impact of **bias** increases as the mean error or error variance due to **bias** increases.
*   The negative impact of **bias** is higher if the **mammogram** is more accurate.
*   A reduction in AUC from 0.837 to 0.831 translates into an additional 237,900 misdiagnoses of patients’ health.
*   Appropriate mechanisms to eliminate or mitigate the **bias** should be adopted.

## 5.4. Value of a Bias-Aware Algorithm for Breast Cancer Diagnosis

*   The value of a **bias-aware algorithm** is examined using the percentage of lost expected life years recovered by accounting for **bias**.
*   The no-**bias** case (β  0 and σ0  0) results in the maximal expected life years.
*   When there is no error variance, σ0  0, the **bias-aware algorithm** is able to recover 100% of the loss incurred by a **bias-blind algorithm**.
*   The value of a **bias-aware algorithm** diminishes when either the mean error or error variance increases, but the value can still be substantial.
*   Mitigating the impact of clinical-risk-information-induced **bias** through a **bias-aware algorithm** alone is likely to be challenging when the radiologist’s **bias**-related behavior is highly unpredictable.

## 5.5. Should the Clinical-Risk Information Be Used for Breast Cancer Diagnosis?

*   Not using the **clinical-risk information** for diagnosing **breast cancer** is sometimes better than using it if it will **bias** the radiologist.
*   The thresholds for the mean error or error variance due to **bias** above which using the **clinical-risk information** leads to an inferior expected utility or AUC are shown in Table 2.
*   The critical role played by the relative discriminative ability of the **clinical-risk information** and **mammogram** in decisions concerning the use of **clinical-risk information** for cancer diagnosis is emphasized.

## 5.6. Impact of Bias When the Accuracy of Clinical-Risk Information Improves

*   As the AUC of **clinical-risk information** increases, the percentage of loss that can be recovered by accounting for **bias** decreases.
*   Correcting for the detrimental effects of **bias** is more difficult at higher **clinical-risk information** AUC values.
*   **Bias** becomes less of an issue and a **bias-aware algorithm** becomes less valuable as the discriminative ability of the **clinical-risk information** improves relative to that of the **mammography**.

# 6. Discussion and Conclusion

*   When algorithms use human-generated input data that suffer from human **biases**, the predictions they generate may exacerbate the errors stemming from such **biases**.
*   The **optimal bias-aware algorithm** can eliminate the adverse impact of **bias** if there is no variability associated with the **bias**-induced error in the radiologist’s assessment.
*   The optimal **bias-aware algorithm** assigns a smaller (larger) weight to the **clinical-risk information** (**radiologist’s mammogram** assessment) when the mean error increases, but the reverse happens when the error variance increases.
*   The **bias-aware algorithm** can significantly improve the expected patient life years.
*   The magnitude of improvement depends critically on the relative discriminative abilities of **clinical-risk information** and **mammogram**.

## 6.1. Translating the Findings Into Clinical Practice

*   Realizing the gains indicated by the study depends on:
    *   Finding ways to incorporate proper weighting of **clinical-risk information** and **mammogram** information.
    *   Reducing, eliminating, or properly adjusting for the **bias** due to **clinical-risk information**.
*   The referring physician should use a decision support system (DSS) that accounts for the unintended over- or underassessment of risk because of the available information.
*   One challenge is that the radiologists a physician deals with could be biased to different degrees, both in terms of **bias** factor (i.e., mean error) and error variance.
*   The relative simplicity of the model makes it possible to incorporate the model into a decision-aid tool.
*   The referring physician’s attitude toward its predictions is another issue to consider.

## 6.2. Future Directions

*   The model can be extended to a general scenario with n attributes and m classification outcomes.
*   Nonlinear aggregation models can provide additional insights into the impact of **bias**.
*   Patient-level **mammography** data would provide better estimates.
*   Estimating the **bias** parameters requires extensive well-designed experiments.
*   The model should be validated by implementing it in a **CDSS** in practice and comparing the actual results with the model predictions.

# Executive summary of 1. Introduction

*   **Algorithms** are increasingly used in decision-making and are prone to human **biases** when they use human-generated data.
*   The study focuses on designing a **bias-aware algorithm** for use in a **CDSS** for **breast cancer diagnosis**.
*   The research aims to answer three key questions about the design and impact of a **bias-aware algorithm** in the context of **breast cancer**.

# Executive summary of 2. XXX (Section 2)

*   The study is related to the literature on cognitive **biases** in medical decision making, the design of **DSS**, and mathematical modeling of **decision biases**.
*   The **anchoring**, confirmation, and **availability biases** can affect **radiological diagnosis**.
*   The study’s approach differs from previous studies by explicitly modeling the source of **bias** as human cognitive flaws.
*   The study takes a prescriptive approach and studies how the **algorithm** should be designed to optimally aggregate information in the presence of biased data.

# Executive summary of 3. Model Description

*   The model considers a patient with an unknown health status and a radiologist assessing a **mammogram** and access to **clinical-risk information**.
*   The error introduced by **bias** is a random variable and a function of a **bias** factor and error variance.
*   The study focuses on exploring the role of **bias** in the design and performance of the **bias-aware algorithm**.
*   The study defines aggregate information, r, and the weight assigned to **clinical-risk information** and **mammogram**.

# Executive summary of 4. Theoretical Analysis

*   The analysis explores the optimal **bias-aware algorithm** based on the AUC and the expected utility objectives, focusing on how **bias** affects **algorithm** performance.
*   The **optimal algorithm**'s characteristics are presented, with key observations.
*   It shows how bias affects utility and discriminative ability and the impact of ignoring **bias**.
*   It also identifies the conditions under which it is suboptimal to use the **clinical-risk information** given that it can bias the radiologist’s assessment.
*   It discusses the impact of both the mean error and the error variance.

# Executive summary of 5. Design and Value of the Bias-Aware Algorithm for Breast Cancer Diagnosis: A Computational Experiment

*   The study uses a **breast-cancer-outcomes database** based on **clinical-risk information** and the medical literature to perform a computational experiment.
*   The parameters for the clinical-risk and mammography distributions are estimated.
*   The impact of radiologists’ **bias** on breast-cancer diagnosis outcomes is quantified.
*   The value of a **bias-aware algorithm** for **breast cancer diagnosis** is examined.
*   The study discusses whether **clinical-risk information** should be used and the impact of **bias** on increasing the accuracy of the **clinical-risk information**.

# Executive summary of 6. Discussion and Conclusion

*   The study examines the design and value of a **bias-aware algorithm** for use in a **CDSS** for **breast cancer diagnosis**.
*   The **optimal bias-aware algorithm** can eliminate the adverse impact of **bias** if there is no variability associated with the **bias**-induced error.
*   The **optimal bias-aware algorithm** assigns a smaller (larger) weight to the **clinical-risk information** (**radiologist’s mammogram** assessment) when the mean error increases, but the reverse happens when the error variance increases.
*   The **bias-aware algorithm** can significantly improve the expected patient life years.
*   The findings can be translated into clinical practice, which involves a proper weighting of **clinical-risk information** and **mammogram** information, and reducing, eliminating, or properly adjusting for the **bias** due to **clinical-risk information**.
*   Future research directions are also suggested.
</details>
